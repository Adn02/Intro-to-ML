{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5727ce83-097e-44fe-8201-912422dd2c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "\n",
    "datapath = '../data-unversions/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(root= datapath, train=True, download = True, transform=transforms.ToTensor())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3fece-8447-4df0-8961-553925de42b5",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "568abd61-d6e9-4bf2-ba59-111f09555510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in cifar10], dim=3)\n",
    "mean = imgs.view(3, -1).mean(dim=1)\n",
    "std = imgs.view(3, -1).std(dim=1)\n",
    "\n",
    "normalize = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)])\n",
    "\n",
    "train_data = datasets.CIFAR10(root= datapath, train=True, download = True, transform=normalize)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "valid_data = datasets.CIFAR10(root= datapath, train=False, download = True, transform=normalize)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a35aa8-76f0-4d29-8e67-7dc719fe0378",
   "metadata": {},
   "source": [
    "Convolution Neural Network Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccb9f36f-1dcd-4f55-9b3e-5986a7e3cf27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Loss: 2.132779671836189, Training Time: 11.84 seconds\n",
      "Epoch 11/300, Loss: 1.3054845870418268, Training Time: 11.77 seconds\n",
      "Epoch 21/300, Loss: 1.0670512146623334, Training Time: 11.70 seconds\n",
      "Epoch 31/300, Loss: 0.9023012640532666, Training Time: 11.75 seconds\n",
      "Epoch 41/300, Loss: 0.7609419397108843, Training Time: 11.72 seconds\n",
      "Epoch 51/300, Loss: 0.6202600797589437, Training Time: 11.77 seconds\n",
      "Epoch 61/300, Loss: 0.47641500122296987, Training Time: 11.63 seconds\n",
      "Epoch 71/300, Loss: 0.3387420295153149, Training Time: 11.69 seconds\n",
      "Epoch 81/300, Loss: 0.2229321424087232, Training Time: 11.70 seconds\n",
      "Epoch 91/300, Loss: 0.14075722430981052, Training Time: 11.65 seconds\n",
      "Epoch 101/300, Loss: 0.08939099554341913, Training Time: 11.77 seconds\n",
      "Epoch 111/300, Loss: 0.05943684597986483, Training Time: 11.72 seconds\n",
      "Epoch 121/300, Loss: 0.042334682717490336, Training Time: 11.70 seconds\n",
      "Epoch 131/300, Loss: 0.03189220657764016, Training Time: 11.71 seconds\n",
      "Epoch 141/300, Loss: 0.025169027446079774, Training Time: 11.69 seconds\n",
      "Epoch 151/300, Loss: 0.02058542067553283, Training Time: 11.64 seconds\n",
      "Epoch 161/300, Loss: 0.017249392776351402, Training Time: 11.76 seconds\n",
      "Epoch 171/300, Loss: 0.014816737573198206, Training Time: 11.73 seconds\n",
      "Epoch 181/300, Loss: 0.012918307684583593, Training Time: 11.72 seconds\n",
      "Epoch 191/300, Loss: 0.011415450324281163, Training Time: 11.68 seconds\n",
      "Epoch 201/300, Loss: 0.010211693515354005, Training Time: 11.75 seconds\n",
      "Epoch 211/300, Loss: 0.009219137342171226, Training Time: 11.73 seconds\n",
      "Epoch 221/300, Loss: 0.008380558306883999, Training Time: 11.79 seconds\n",
      "Epoch 231/300, Loss: 0.007682815464499501, Training Time: 11.74 seconds\n",
      "Epoch 241/300, Loss: 0.007079287728125507, Training Time: 11.71 seconds\n",
      "Epoch 251/300, Loss: 0.006557343519034766, Training Time: 11.68 seconds\n",
      "Epoch 261/300, Loss: 0.006099793650043064, Training Time: 11.74 seconds\n",
      "Epoch 271/300, Loss: 0.00570335038860167, Training Time: 11.69 seconds\n",
      "Epoch 281/300, Loss: 0.005348256658059583, Training Time: 11.67 seconds\n",
      "Epoch 291/300, Loss: 0.005033745771239411, Training Time: 11.88 seconds\n",
      "Total Training Time: 3519.58 seconds\n",
      "Test Accuracy: 69.62%\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = Net().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 300\n",
    "total_start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    losses = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {losses/len(train_loader)}, Training Time: {training_time:.2f} seconds')\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_training_time = total_end_time - total_start_time\n",
    "print(f'Total Training Time: {total_training_time:.2f} seconds')\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in valid_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\\\n",
    "\n",
    "valid_accuracy = correct / total\n",
    "print(f'Test Accuracy: {valid_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b778be-6e0a-4aaf-bb4a-ac301cc4a37d",
   "metadata": {},
   "source": [
    "Extended Convolution Neural Network Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e33e5551-e3b0-4c58-830a-5c34ba9229e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Loss: 2.2840374397758634, Training Time: 12.56 seconds\n",
      "Epoch 11/300, Loss: 1.4350693683859177, Training Time: 11.54 seconds\n",
      "Epoch 21/300, Loss: 1.1854603166619861, Training Time: 11.56 seconds\n",
      "Epoch 31/300, Loss: 0.9991389659071914, Training Time: 11.56 seconds\n",
      "Epoch 41/300, Loss: 0.8614900197764657, Training Time: 11.49 seconds\n",
      "Epoch 51/300, Loss: 0.7440521800586678, Training Time: 11.44 seconds\n",
      "Epoch 61/300, Loss: 0.6382345359293375, Training Time: 11.55 seconds\n",
      "Epoch 71/300, Loss: 0.5386070913884858, Training Time: 11.53 seconds\n",
      "Epoch 81/300, Loss: 0.44279941085127783, Training Time: 11.54 seconds\n",
      "Epoch 91/300, Loss: 0.3498156610649897, Training Time: 11.55 seconds\n",
      "Epoch 101/300, Loss: 0.2595750564376818, Training Time: 11.48 seconds\n",
      "Epoch 111/300, Loss: 0.18173011208831386, Training Time: 11.53 seconds\n",
      "Epoch 121/300, Loss: 0.116232008097654, Training Time: 11.53 seconds\n",
      "Epoch 131/300, Loss: 0.06327274306221452, Training Time: 11.52 seconds\n",
      "Epoch 141/300, Loss: 0.030406432321190273, Training Time: 11.52 seconds\n",
      "Epoch 151/300, Loss: 0.0159665501894881, Training Time: 11.49 seconds\n",
      "Epoch 161/300, Loss: 0.00987952942395391, Training Time: 11.52 seconds\n",
      "Epoch 171/300, Loss: 0.006947840517327208, Training Time: 11.53 seconds\n",
      "Epoch 181/300, Loss: 0.005359023789806984, Training Time: 11.56 seconds\n",
      "Epoch 191/300, Loss: 0.005151326005628317, Training Time: 11.53 seconds\n",
      "Epoch 201/300, Loss: 0.003681466118538346, Training Time: 11.46 seconds\n",
      "Epoch 211/300, Loss: 0.002927576622899481, Training Time: 11.61 seconds\n",
      "Epoch 221/300, Loss: 0.0024592983399375425, Training Time: 11.53 seconds\n",
      "Epoch 231/300, Loss: 0.0021109212819583386, Training Time: 11.55 seconds\n",
      "Epoch 241/300, Loss: 0.001854420374288365, Training Time: 11.51 seconds\n",
      "Epoch 251/300, Loss: 0.00164842018181302, Training Time: 11.48 seconds\n",
      "Epoch 261/300, Loss: 0.0014831697046104283, Training Time: 11.57 seconds\n",
      "Epoch 271/300, Loss: 0.0013382325703185827, Training Time: 11.51 seconds\n",
      "Epoch 281/300, Loss: 0.0012238203051174684, Training Time: 11.54 seconds\n",
      "Epoch 291/300, Loss: 0.0011240569229909712, Training Time: 11.53 seconds\n",
      "Total Training Time: 3457.38 seconds\n",
      "Test Accuracy: 71.66%\n"
     ]
    }
   ],
   "source": [
    "class ExtendedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExtendedNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = ExtendedNet().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 300\n",
    "total_start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    losses = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {losses/len(train_loader)}, Training Time: {training_time:.2f} seconds')\n",
    "\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_training_time = total_end_time - total_start_time\n",
    "print(f'Total Training Time: {total_training_time:.2f} seconds')\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in valid_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "valid_accuracy = correct / total\n",
    "print(f'Test Accuracy: {valid_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
